<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Hysteria</title>
    <link>http://yoursite.com/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Keep Calm</description>
    <pubDate>Thu, 30 Aug 2018 16:12:52 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>新评论gitalk系统踩坑</title>
      <link>http://yoursite.com/2018/08/30/gitment%E2%80%94%E2%80%94config/</link>
      <guid>http://yoursite.com/2018/08/30/gitment%E2%80%94%E2%80%94config/</guid>
      <pubDate>Thu, 30 Aug 2018 15:39:58 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;新评论系统踩坑经历&quot;&gt;&lt;a href=&quot;#新评论系统踩坑经历&quot; class=&quot;headerlink&quot; title=&quot;新评论系统踩坑经历&quot;&gt;&lt;/a&gt;新评论系统踩坑经历&lt;/h1&gt;&lt;h2 id=&quot;选择过程&quot;&gt;&lt;a href=&quot;#选择过程&quot; class=&quot;headerli
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="新评论系统踩坑经历"><a href="#新评论系统踩坑经历" class="headerlink" title="新评论系统踩坑经历"></a>新评论系统踩坑经历</h1><h2 id="选择过程"><a href="#选择过程" class="headerlink" title="选择过程"></a>选择过程</h2><p>网易云跟帖和多说都挂掉了，所以急需一款新的比较好用的跟帖评论工具。比较了下面几种：</p><ul><li>hexo官方文档里的扩展：disqus，因为墙你懂得</li><li>来必力 同样存在加载慢的问题</li><li>gitalk 看起来不错，依托github issue, 支持markdown</li><li>hypercomments，唯一缺点不支持markdown</li></ul><p>好吧那就选gitalk吧</p><h2 id="实际工作"><a href="#实际工作" class="headerlink" title="实际工作"></a>实际工作</h2><p>其实按照网上多如牛毛的添加gitalk教程来就行，我随手在这贴一个：<a href="https://www.jianshu.com/p/9be29ed2f4b7" target="_blank" rel="noopener">https://www.jianshu.com/p/9be29ed2f4b7</a> ，感谢这位的分享，虽然我大概看的不是他的分享……只是表达一下随手就能搜出一斤的情况。</p><blockquote><p>那说好的坑呢？</p></blockquote><p>别急……有俩坑。</p><p>第一个坑在github应用创建的时候，如果你绑定了自己的个性化域名，homepage url和回调url一定填自己绑定后的域名。这个我开始绑定的github.io，回调就报错。</p><p>第二个坑就出在网上花花绿绿不同教程上了。主要是gitalk配置字段的问题。不论你选择哪一种方法，都会有在主题配置文件添加字段的选项，如下：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gitalk</span></span><br><span class="line"><span class="attr">gitalk:</span> </span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  clientID:</span> <span class="string">'your clientID'</span>    </span><br><span class="line"><span class="attr">  clientSecret:</span> <span class="string">'your clientSecret'</span>   </span><br><span class="line"><span class="attr">  repo:</span> <span class="string">Blog_comments</span>    </span><br><span class="line"><span class="attr">  owner:</span> <span class="string">erbiduo</span>   </span><br><span class="line"><span class="attr">  admin:</span> <span class="string">erbiduo</span></span><br><span class="line"><span class="attr">  distractionFreeMode:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">gitalk:</span><br><span class="line">  enable: <span class="literal">true</span></span><br><span class="line">  githubID: github帐号  # 例：asdfv1929   </span><br><span class="line">  repo: 仓库名称   # 例：asdfv1929.github.io</span><br><span class="line">  ClientID:<span class="built_in"> Client </span>ID</span><br><span class="line">  ClientSecret:<span class="built_in"> Client </span>Secret</span><br><span class="line">  adminUser: github帐号 #指定可初始化评论账户</span><br><span class="line">  distractionFreeMode: <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>这是我在网上找的两个版本的主题文件配置内容，你猜哪个是对的？</p><p>这就需要看你在themes/next/layout/_third-party/comments/gitalk.swig内的字段怎么写的了，swig文件添加进去的内容：<br><figure class="highlight django"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">if</span></span> page.comments &amp;&amp; theme.gitalk.enable %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"https://unpkg.com/gitalk/dist/gitalk.css"</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://unpkg.com/gitalk/dist/gitalk.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml">   <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="undefined"></span></span></span><br><span class="line"><span class="xml">        var gitalk = new Gitalk(&#123;</span></span><br><span class="line"><span class="xml">          clientID: '</span><span class="template-variable">&#123;&#123; theme.gitalk.ClientID &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          clientSecret: '</span><span class="template-variable">&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          repo: '</span><span class="template-variable">&#123;&#123; theme.gitalk.repo &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          owner: '</span><span class="template-variable">&#123;&#123; theme.gitalk.githubID &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          admin: ['</span><span class="template-variable">&#123;&#123; theme.gitalk.adminUser &#125;&#125;</span><span class="xml">'],</span></span><br><span class="line"><span class="xml">          id: location.pathname,</span></span><br><span class="line"><span class="xml">          distractionFreeMode: '</span><span class="template-variable">&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;</span><span class="xml">'</span></span><br><span class="line"><span class="xml">        &#125;)</span></span><br><span class="line"><span class="xml">        gitalk.render('gitalk-container')           </span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="xml"></span></span><br></pre></td></tr></table></figure></p><p>很明显，如果在部署的时候解析你主题文件的配置，字段里Gitalk对象肯定要和配置文件里字段一致，也就是说你的配置文件里gitalk下其他字段要跟Gitalk对象内的字段一致，gitalk.ClientID对应在主题配置文件下的就是ClientID字段，owner:gitalk.githubID和主题配置下githubID字段要这样一一对应，我按照某些教程搭建的时候就出了问题，调试了一下找到了这俩坑。其他的基本就按教程配置就行，最后注意swig中字段和theme下的config.yml一致就可以。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/08/30/gitment%E2%80%94%E2%80%94config/#disqus_thread</comments>
    </item>
    
    <item>
      <title>歇斯底里</title>
      <link>http://yoursite.com/2018/08/27/hysteria/</link>
      <guid>http://yoursite.com/2018/08/27/hysteria/</guid>
      <pubDate>Mon, 27 Aug 2018 14:17:42 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;不得不说社会矛盾现在可能逐渐都折射到学校里了，象牙塔里弥散着一种好闻的腐朽气息，实在让人觉得哭笑不得。&lt;/p&gt;
&lt;p&gt;上研一年，唯一感受到的情绪就是极端的荒诞。从各种角度来说，这一年基本可以称的上是魔幻现实主义的一年了。很多闹剧目前看起来跟喜剧别无二致。暴民的狂欢和暴动一直
        
      
      </description>
      
      <content:encoded><![CDATA[<p>不得不说社会矛盾现在可能逐渐都折射到学校里了，象牙塔里弥散着一种好闻的腐朽气息，实在让人觉得哭笑不得。</p><p>上研一年，唯一感受到的情绪就是极端的荒诞。从各种角度来说，这一年基本可以称的上是魔幻现实主义的一年了。很多闹剧目前看起来跟喜剧别无二致。暴民的狂欢和暴动一直在推进，大概以下一句话可以概括总结社会百态：</p><blockquote><p>“每个人都是水明星，都是嗨明星” — 抽象圣经</p></blockquote><p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1535390574380&amp;di=901de46ab16b2e9610a712c2752c0b0f&amp;imgtype=0&amp;src=http%3A%2F%2Fn.sinaimg.cn%2Fsinacn%2Fw429h513%2F20171213%2F1d5a-fypsqiz5453383.jpg" alt="avatar"></p><p>我同样也暴动了一年。这一年感觉天天没啥心情也没啥目标，机械性的重复劳动，重复码，看看文章，学学数学，然后回屋开始焦虑。再这样继续下去，我都觉得有必要画一条失眠曲线来表现我的悲惨。睡着慢还不够，每每隔个几天我都会有在睡梦中坠落的奇妙体验，这种感觉让我欲罢不能，莫名奇妙的愉悦，唯一的缺点就是半夜容易醒。</p><p>这到不怎么奇怪，毕竟焦虑我觉得在天朝研究生中实在是太普遍了，见怪不怪。每天白天疯狂看paper刷代码搭framework或是干一干水水的工程，晚上懈怠下来大概率会焦虑一下嘛，也正常。夹在导师和毕业要求中间，每个人不是失去了尊严，就是失去了自我：我可以循规蹈矩，但是必须放弃尊严；我也可以装死装蠢不听话，但是这样就丧失自我。这种里外不是自己的感觉非常糟糕，伴随着临近毕业的社会压力，往往越来越糟，陷入一个我好想毕业啊 -&gt; 房价好贵，我买不起 -&gt; 还是接着上学吧 -&gt; 上学上够了这种死循环中。而且现在工作岗位竞争也确实竞争激烈，不得不感叹一句晚生了几年。毕竟社会真相大概就是资本决定一切，资本世界的法则我看起来只有一条：</p><blockquote><p>优先进场</p></blockquote><p>这大概是最好赢的办法。很多又蠢又坏的人总在宣传自己无耻的成功学，然而成功的本质就是优先进场。然后无数神经病盯着脑残式的鸡汤一直吮来吮去，直到最后价值观全都带跑偏了，蠢货就能以2的指数倍疯狂增长，然后开始画大饼收割。这种成功最厉害的影响还在于一点，就是让很多不自知的人做上了春秋大梦，开始自诩精英，梦想自己是个时代弄潮儿。这种人可真是太多了，之后这些腌臜构成了社会价值观主流，再以自己无耻至极的价值观强行审判我。我可去你妈的。我没啥追求，只求你自己多蠢多肮脏随意，但是请别拿这个视角看我。然而在大环境下，这种诉求大概是一种奢求。</p><p>我最想抱怨的就是这种奇形怪状的价值观。太多人完全信奉利益驱动型的形式准则，但是我着实不喜欢这个思维方式。腐朽的价值观带来太多戾气和势利，没人不喜欢钱，这毕竟是这个世界最有力的价值交换工具，但是整个社会对金钱的渴望达到一种病态程度的时候，带来的负面影响实在是太大了。信誉与公信力的下降，带来的问题绝不是一时质疑，如果您总觉得钻个空子就是别人都傻，那我也确实说不出话来。</p><p>只是很可惜，我在荒诞的环境里见了太多典型了。我现在搞不清楚到底是我格格不入，还是我高风亮节了。压迫并不能换来反抗，包容也不能带来收益。而更魔幻的其实还是所谓同龄人的相处，满嘴闭嘴都是百元人民币的年代，总让我产生一种我活在一堆资本家中间的错觉。我其实对自诩社会精英的一类人一向反感，占着我们无产阶级的坑带入资本家立场，反过来想当p民头上三座大山。这到底算是抽象还是现实？我觉得这大概是太现实了一点。然而很多人对现实主义的理解也有偏差。我信奉节能一点的现实主义，那就是比普通人过的好一点算是成功。现实从来不是空想或是势利，好歹也是要先看清现实再谈现实主义的吧？</p><blockquote><p>我大概听了各种过于现实的例子。比如说女生说男生没房我要找个北京有房的之流这种故事。我一直觉得从小到大听过最搞笑的说法就是婊子总说女生比男生更成熟。说这种话不觉得搞笑么？靠性别换来的利益变现什么时候变成成熟的标志了？容我先大笑三声。鸡比鸭多说明鸡比鸭高贵？笑掉大牙。</p></blockquote><p>没人跟过的更好过不去。底线这个东西在现在确实被模糊的很厉害，也搞不清楚是人类文明进化的一种形式还是浪漫主义倒退的具体表现。</p><p>只不过问题是夹在社会奇妙价值观和周围环境中间的一批人，日子着实也不太好过。正反从来都是相对的，对错也一样，都是一种微妙的平衡，只不过目前我的正确处在平衡里错误的一方。</p><p>“请品味我的声嘶力竭”。</p><p>这大概就是我唯一能说的。这样的生活着实没花光我所有力气，但是大概磨掉了我本来就不多的棱角。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/08/27/hysteria/#disqus_thread</comments>
    </item>
    
    <item>
      <title>pose estimation tutorials</title>
      <link>http://yoursite.com/2018/08/19/%E5%88%86%E4%BA%AB/</link>
      <guid>http://yoursite.com/2018/08/19/%E5%88%86%E4%BA%AB/</guid>
      <pubDate>Sun, 19 Aug 2018 02:28:55 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;分享一版整理的一些姿态估计心得的repo：&lt;a href=&quot;https://github.com/IcewineChen/Pose-estimation_tutorials&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com
        
      
      </description>
      
      <content:encoded><![CDATA[<p>分享一版整理的一些姿态估计心得的repo：<a href="https://github.com/IcewineChen/Pose-estimation_tutorials" target="_blank" rel="noopener">https://github.com/IcewineChen/Pose-estimation_tutorials</a></p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/08/19/%E5%88%86%E4%BA%AB/#disqus_thread</comments>
    </item>
    
    <item>
      <title>谈谈gluon和其他我用过的框架</title>
      <link>http://yoursite.com/2018/07/29/gluon/</link>
      <guid>http://yoursite.com/2018/07/29/gluon/</guid>
      <pubDate>Sun, 29 Jul 2018 14:35:16 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;关于gluon&quot;&gt;&lt;a href=&quot;#关于gluon&quot; class=&quot;headerlink&quot; title=&quot;关于gluon&quot;&gt;&lt;/a&gt;关于gluon&lt;/h2&gt;&lt;p&gt;前几天跟小伙伴们讨论到了几个问题，突然讨论这个事情：比如说我的数据load进来之后，想把不同的bat
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="关于gluon"><a href="#关于gluon" class="headerlink" title="关于gluon"></a>关于gluon</h2><p>前几天跟小伙伴们讨论到了几个问题，突然讨论这个事情：比如说我的数据load进来之后，想把不同的batch并行，这样该怎么弄？</p><p>我很喜欢pytorch，但是我大部分时间对pytorch的并行调用dataparallel时的实际操作是把数据一个batch拆分，然后并行到设备上，很明显不符合需求，要是改动还得对底层动刀。然后突然想到嗯，好像除了这个问题，有些时候去符号式这种东西，还真不太适合快速复现或者验证想法。目前大部分时间复现我确实都优先考虑mxnet做。如果不太需要自定义层，基本才会考虑pytorch。</p><p>然后呢……就是安利一发mxnet了。顺带也相当于总结下我对这些框架的使用体验。最早在16年的时候，我猜大家肯定都在耍……caffe。那时候出于我写c++写习惯了的，一度出现了c++是世界上最好的语言的错觉……事实上caffe确实定制度好，自由度高，python接口也问题不大，但是确实需要自定义的太多，编译各种问题吐血，而且出于语言习惯，我更乐意从头写个layer，backward慢慢磨，然而这确实相当浪费时间。而且到后来越来越多的文章都在用tensorflow，出于代码的编写和调试时间成本，还是基本放弃了caffe，除非有时候看一些早期的文章，放出的代码基于caffe还会看一看，其他时候基本不考虑caffe了。caffe2出了以后，detectron似乎也没能完全拯救他，我是编译了一份扔一边了。不过当年在公司实习的时候，大家确实也都在用caffe，我的结论就是是出于部署和性能考量，caffe比较适合。然而mxnet在分布式和部署上我觉得不比caffe差，事实也确实是后续业务也开始转向mxnet。总体而言caffe在科研上开始没用tensorflow或是pytorch那么闪光了。</p><p>之后tensorflow。没什么可多说的，基本上你肯定得会。放tensorflow代码的文章多如牛毛，文章多，社区好，早期时候带自动微分这种牛逼功能，背景牛逼，而且符号式编程其实更符合我的思维方式（也可能有人对符号式编程写model不习惯，这个只是个人意见）。然后绝大部分时间我research绝不会写tensorflow的代码。为啥……那个调试真的痛苦的要死，我对tensorflow的更新最终停在了estimator出来的那个版本。虽然后期的eager Execution机制引入动态图，但是本质上依然只是一个功能，整个框架依然是基于静态图开发的。tensorflow对于实现你表达的思路是个非常非常优秀的框架，然而确实会给你中间的一些验证带来很多不必要的麻烦，而且相对比较笨重。对于科研实验来说，很多东西是相当冗余的，对于要求快速实验验证想法的research来说这个问题还是比较致命的。</p><p>接下来才是比较重要的比较。我觉得对于大部分来说大概还是偏好pytorch和mxnet一点（其实并没mxnet什么毛关系）。支持动态图，当时刚转到pytorch上的我觉得这简直是最棒的机制了。动态图在调试上优势太大，中间变量查看十分十分方便，对于快速验证模型的一些问题提，比如说中间shape，dtype以及各种问题供了巨大便利，不需要静态图的各种包装以及session去跑。在同样采用动态图的基础上，mxnet和pytorch的核心区别，我觉得大概就在符号编程上了。pytorch继承了torch当年的优良意志：我们绝对不用符号式编程……符号式编程简单来说就是把变量就定义成一个符号，之后把数据扔进来的时候再通过name告诉他哪喂什么就好，相对来说很适合直接扔一个symbol在这，最后再考虑数据的问题就好，可以把模型定义单独作为一件事情。而pytorch数据流向直接定义调用就可以，最后需要求导记得用variable封装好即可。</p><p>然而gluon出来以后，我觉得mxnet确实兼顾了各家之长。gluon里两点让我觉得特别优秀。第一点就是不得不提的混合编程，这点看下面代码就知道：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Hourglass</span>(<span class="title">gluon</span>.<span class="title">nn</span>.<span class="title">HybridBlock</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>,n,nModules,nFeats)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">super</span>(Hourglass,<span class="keyword">self</span>).__init_<span class="number">_</span>()</span><br><span class="line">        <span class="keyword">self</span>.n = n</span><br><span class="line">        <span class="keyword">self</span>.nModules = nModules</span><br><span class="line">        <span class="keyword">self</span>.nFeats = nFeats</span><br><span class="line"></span><br><span class="line">        <span class="keyword">self</span>.up1<span class="number">_</span> = gluon.nn.HybridSequential()</span><br><span class="line">        <span class="keyword">self</span>.low1<span class="number">_</span> = gluon.nn.HybridSequential()</span><br><span class="line">        <span class="keyword">self</span>.low2<span class="number">_</span> = gluon.nn.HybridSequential()</span><br><span class="line">        <span class="keyword">self</span>.low3<span class="number">_</span> = gluon.nn.HybridSequential()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.up1<span class="number">_</span>.add(Residual(in_channels=<span class="keyword">self</span>.nFeats,out_channels=<span class="keyword">self</span>.nFeats))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">self</span>.low1 = gluon.nn.MaxPool2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>),strides=(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.low1<span class="number">_</span>.add(Residual(in_channels=<span class="keyword">self</span>.nFeats,out_channels=<span class="keyword">self</span>.nFeats))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.n &gt; <span class="number">1</span><span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.low2 = Hourglass(n=n-<span class="number">1</span>,nModules=<span class="keyword">self</span>.nModules,nFeats = <span class="keyword">self</span>.nFeats)</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">self</span>.low2<span class="number">_</span>.add(Residual(in_channels=nFeats,out_channels=nFeats))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.low3<span class="number">_</span>.add(Residual(in_channels=<span class="keyword">self</span>.nFeats,out_channels=nFeats))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">self</span>.up2 = gluon.nn.Conv2DTranspose(channels=<span class="keyword">self</span>.nFeats,kernel_size=(<span class="number">2</span>,<span class="number">2</span>),strides=(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hybrid_forward</span><span class="params">(<span class="keyword">self</span>,F,x)</span></span><span class="symbol">:</span></span><br><span class="line">        up1 = x</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">            up1 = <span class="keyword">self</span>.up1<span class="number">_</span>[i](up1)</span><br><span class="line">        </span><br><span class="line">        low1 = <span class="keyword">self</span>.low1(x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">            low1 = <span class="keyword">self</span>.low1<span class="number">_</span>[i](low1)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.n &gt; <span class="number">1</span><span class="symbol">:</span></span><br><span class="line">            low2 = <span class="keyword">self</span>.low2(low1)</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            low2 = low1</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">                low2 = <span class="keyword">self</span>.low2<span class="number">_</span>[i](low2)</span><br><span class="line">        </span><br><span class="line">        low3 = low2</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">            low3 = <span class="keyword">self</span>.low3<span class="number">_</span>[i](low3)</span><br><span class="line">        <span class="comment"># gluon的nn里没有upsample，混合直接调用ndarray的sample</span></span><br><span class="line">        <span class="comment"># up2 = F.UpSampling(low3,sample_type='bilinear',scale=2)</span></span><br><span class="line">        up2 = <span class="keyword">self</span>.up2(low3)</span><br><span class="line">        <span class="keyword">return</span> up1 + up2</span><br></pre></td></tr></table></figure></p><p>这是我定义的一个Hourglass结构，只需要你的net或者模块继承hybridblock，forward时候就需要实现一个hybrid_forward(self,F,x)。这个F是区别于非混合式forward的量，调用时候F.function就会自动找你的function从什么里调用，是从符号式还是正常数值计算的ndarray的包里去找。这个功能真的相当人性，一部分ndarray中实现的函数，在symbol包内或是gluon.nn包内是没有的，这样使得mxnet的可用性和使用体验更好，用户大概只需要关注结构定义就可以。当然逻辑比较简单的网络可以直接Sequential add即可。</p><p>二是几乎没什么学习成本。这个结构看着熟不熟悉？基本就和pytorch里的结构定义是一样的。有大量的人都在主用pytorch，这样的风格从pytorch迁移代码十分方便。比起mxnet symbol相对更繁琐的定义，这种class内部定义层，再在forward连接的方式大家确实写起来十分习惯，而且也比较符合我脑子里想像的dl定义范式和思维习惯。mxnet目前唯一的问题大概api更新太快，之前每一版更新变动都不小，还处在高速发展，其实也就是不太稳定的阶段，但是bug也已经减少了很多，可用性高而且复现好用，个人觉得框架选择的话，pytorch最轻松上手，mxnet大概是使用起来感觉最好的。如果硬要选框架自己写代码，主役pytorch或是mxnet都是好选择，然而考虑到科研中的泛用度，mxnet确实略逊pytorch一筹，mxnet代码的文章不是很多。但是就个人喜好而言，mxnet在gluon引入以后可能更好一点。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/07/29/gluon/#disqus_thread</comments>
    </item>
    
    <item>
      <title>pytorch-hg-3d代码分析</title>
      <link>http://yoursite.com/2018/07/16/pytorch-hg-3d%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <guid>http://yoursite.com/2018/07/16/pytorch-hg-3d%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <pubDate>Mon, 16 Jul 2018 14:02:25 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;上次组会分享了CVPR2018的3d pose估计文章 3D Human Pose Estimation in the Wild by Adversarial Learning,文章中提到一种用GAN的方式生成3D in the wild估计的方法。最近准备复现，顺带在这里
        
      
      </description>
      
      <content:encoded><![CDATA[<p>上次组会分享了CVPR2018的3d pose估计文章 3D Human Pose Estimation in the Wild by Adversarial Learning,文章中提到一种用GAN的方式生成3D in the wild估计的方法。最近准备复现，顺带在这里先分析一下结构中Generator，顺带分析一下代码</p><p>生成器的结构参见Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach，感谢作者，该结构以stacked hourglass为base network做一个2d keypoint估计，然后扔进3d regression得到最后的结果。数据集选用了有3d ground truth和没有ground truth的in the wild 2d集拼合，整体结构上在2d估计中抽出了中间层信息送入回归器，迁移了in the wild的信息。</p><h2 id="pytorch网络代码分析"><a href="#pytorch网络代码分析" class="headerlink" title="pytorch网络代码分析"></a>pytorch网络代码分析</h2><p>先贴一段核心网络结构的代码：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HourglassNet3D</span>(<span class="title">nn</span>.<span class="title">Module</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, nStack, nModules, nFeats, nRegModules)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">super</span>(HourglassNet3D, <span class="keyword">self</span>).__init_<span class="number">_</span>()</span><br><span class="line">    <span class="keyword">self</span>.nStack = nStack</span><br><span class="line">    <span class="keyword">self</span>.nModules = nModules</span><br><span class="line">    <span class="keyword">self</span>.nFeats = nFeats</span><br><span class="line">    <span class="keyword">self</span>.nRegModules = nRegModules</span><br><span class="line">    <span class="keyword">self</span>.conv1<span class="number">_</span> = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, bias = True, kernel_size = <span class="number">7</span>, stride = <span class="number">2</span>, padding = <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">self</span>.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">    <span class="keyword">self</span>.relu = nn.ReLU(inplace = True)</span><br><span class="line">    <span class="keyword">self</span>.r1 = Residual(<span class="number">64</span>, int(<span class="number">128</span>))</span><br><span class="line">    <span class="keyword">self</span>.maxpool = nn.MaxPool2d(kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">self</span>.r4 = Residual(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">    <span class="keyword">self</span>.r5 = Residual(<span class="number">128</span>, <span class="keyword">self</span>.nFeats)</span><br><span class="line">    </span><br><span class="line">    _hourglass, _Residual, _lin<span class="number">_</span>, _tmpOut, _ll<span class="number">_</span>, _tmpOut<span class="number">_</span>, _reg<span class="number">_</span> = [], [], [], [], [], [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nStack)<span class="symbol">:</span></span><br><span class="line">      <span class="comment"># n阶的hourglass</span></span><br><span class="line">      _hourglass.append(Hourglass(<span class="number">4</span>, <span class="keyword">self</span>.nModules, <span class="keyword">self</span>.nFeats))</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">      <span class="comment"># 连接stacks间的基本残差单元</span></span><br><span class="line">        _Residual.append(Residual(<span class="keyword">self</span>.nFeats, <span class="keyword">self</span>.nFeats))</span><br><span class="line">      lin = nn.Sequential(nn.Conv2d(<span class="keyword">self</span>.nFeats, <span class="keyword">self</span>.nFeats, bias = True, kernel_size = <span class="number">1</span>, stride = <span class="number">1</span>), </span><br><span class="line">                          nn.BatchNorm2d(<span class="keyword">self</span>.nFeats), <span class="keyword">self</span>.relu)</span><br><span class="line">      _lin<span class="number">_</span>.append(lin)</span><br><span class="line">      _tmpOut.append(nn.Conv2d(<span class="keyword">self</span>.nFeats, ref.nJoints, bias = True, kernel_size = <span class="number">1</span>, stride = <span class="number">1</span>))</span><br><span class="line">      _ll<span class="number">_</span>.append(nn.Conv2d(<span class="keyword">self</span>.nFeats, <span class="keyword">self</span>.nFeats, bias = True, kernel_size = <span class="number">1</span>, stride = <span class="number">1</span>))</span><br><span class="line">      _tmpOut<span class="number">_</span>.append(nn.Conv2d(ref.nJoints, <span class="keyword">self</span>.nFeats, bias = True, kernel_size = <span class="number">1</span>, stride = <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)<span class="symbol">:</span></span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="keyword">self</span>.nRegModules)<span class="symbol">:</span></span><br><span class="line">        _reg<span class="number">_</span>.append(Residual(<span class="keyword">self</span>.nFeats, <span class="keyword">self</span>.nFeats))</span><br><span class="line">    <span class="comment"># append部分对应stackhourglass中的沙漏型结构，将其中用的residual模块和n个Stack整理进sequential的形式方便之后再循环里调用</span></span><br><span class="line">    <span class="comment"># modulelist的取法其实基本跟list一样，封装在modulelist里会检测到每一个的hook，直接包装在list里，每一个单元内部的参数会初始不到</span></span><br><span class="line">    <span class="keyword">self</span>.hourglass = nn.ModuleList(_hourglass)</span><br><span class="line">    <span class="keyword">self</span>.Residual = nn.ModuleList(_Residual)</span><br><span class="line">    <span class="keyword">self</span>.lin<span class="number">_</span> = nn.ModuleList(_lin<span class="number">_</span>)</span><br><span class="line">    <span class="keyword">self</span>.tmpOut = nn.ModuleList(_tmpOut)</span><br><span class="line">    <span class="keyword">self</span>.ll<span class="number">_</span> = nn.ModuleList(_ll<span class="number">_</span>)</span><br><span class="line">    <span class="keyword">self</span>.tmpOut<span class="number">_</span> = nn.ModuleList(_tmpOut<span class="number">_</span>)</span><br><span class="line">    <span class="keyword">self</span>.reg<span class="number">_</span> = nn.ModuleList(_reg<span class="number">_</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">self</span>.reg = nn.Linear(<span class="number">4</span> * <span class="number">4</span> * <span class="keyword">self</span>.nFeats, ref.nJoints)</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(<span class="keyword">self</span>, x)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="comment"># 将定义了的层按顺序传递，构建整个网络的forward顺序</span></span><br><span class="line">    x = <span class="keyword">self</span>.conv1<span class="number">_</span>(x)</span><br><span class="line">    x = <span class="keyword">self</span>.bn1(x)</span><br><span class="line">    x = <span class="keyword">self</span>.relu(x)</span><br><span class="line">    x = <span class="keyword">self</span>.r1(x)</span><br><span class="line">    x = <span class="keyword">self</span>.maxpool(x)</span><br><span class="line">    x = <span class="keyword">self</span>.r4(x)</span><br><span class="line">    x = <span class="keyword">self</span>.r5(x)</span><br><span class="line">    </span><br><span class="line">    out = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.nStack)<span class="symbol">:</span></span><br><span class="line">      hg = <span class="keyword">self</span>.hourglass[i](x)</span><br><span class="line">      ll = hg</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="keyword">self</span>.nModules)<span class="symbol">:</span></span><br><span class="line">        ll = <span class="keyword">self</span>.Residual[i * <span class="keyword">self</span>.nModules + j](ll)</span><br><span class="line">      ll = <span class="keyword">self</span>.lin<span class="number">_</span>[i](ll)</span><br><span class="line">      tmpOut = <span class="keyword">self</span>.tmpOut[i](ll)</span><br><span class="line">      out.append(tmpOut)</span><br><span class="line">      </span><br><span class="line">      ll<span class="number">_</span> = <span class="keyword">self</span>.ll<span class="number">_</span>[i](ll)</span><br><span class="line">      tmpOut<span class="number">_</span> = <span class="keyword">self</span>.tmpOut<span class="number">_</span>[i](tmpOut)</span><br><span class="line">      <span class="comment"># 取多层信息，作为下一个hourglass的输入，也保存信息到送入reg的x里</span></span><br><span class="line">      x = x + ll<span class="number">_</span> + tmpOut<span class="number">_</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)<span class="symbol">:</span></span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="keyword">self</span>.nRegModules)<span class="symbol">:</span></span><br><span class="line">        x = <span class="keyword">self</span>.reg<span class="number">_</span>[i * <span class="keyword">self</span>.nRegModules + j](x)</span><br><span class="line">      x = <span class="keyword">self</span>.maxpool(x)</span><br><span class="line">      </span><br><span class="line">    x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    reg = <span class="keyword">self</span>.reg(x)</span><br><span class="line">    out.append(reg)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></p><p>这就是3d stacked hourglass结构的代码。关于一个nn.Module的代码怎么写，其实参照pytorch源码的Module写就可以，由于自动微分这种东西的存在，继承Module时需要只定义init和forward函数即可。在init函数中，我们定义需要的层，需要的结构，然后在forward中，定义层的连接，也就是网络的结构。这段代码描述了生成器的结构，总体来说，nStack就是单个stacked hourglass的阶数，modules是使用级联的模块数，residual是一个残差结构。ll是我们一开始抽出来的stacked的输出层和中间层的和，也就是抽出层再加上输出的结果，之后在输入维度上做整合。reg是3d信息回归器的结构。在forward中，按照stacked hourglass的方法先加了conv+bn+relu+残差+max pooling的结构调整网络输入，之后搭建2d的级联结构，同时把每个stacked结构中的中间一层抽出来,和每个级联的stack一起送去3d regression。具体的代码注释和一些修改我都放在了我fork的repository里，欢迎来看整个注释和代码啊，现在还没彻底完成，还在这个的基础上加入GAN部分的代码（主要是multi-source的鉴别器）去复现GAN-hg-3d。准备在这个结构上调整，看看in the wild的3d pose的效果如何。大概觉得这个方向在工业界落地上可能还有点价值……以前实习的时候组里也有人做过2d的gesture，问题本质上都差不多。理论上行为这一块市场很大，pose的工作还是很有价值的。</p><p>pytorch在大部分时间是不需要定义backward的，基本上直接继承nn.Module就可以实现。不过有时候需要我们自定义loss，这时候loss从function里继承，这里其实本质上你也可以直接写在新的Module里，但是你可以尝试一下在Module的backward里面加上一些print，之后从外部调一下试试看。这时候是不会执行的。因为本身Module底层就是要进行backward的操作，每一步操作的时候都会生成一个Function的子类，最后把这些子类的forward和backward连接到一起。所以这些时候你在module内部写一个backward它根本就不会执行，因为实际上真的调用的是基于Function的backward操作。所以如果有大量自定义而pytorch的底层又没有实现的计算，可以直接自定义一个继承自Function的class，然后再用module封装进去。这也是官方文档的做法，在neural style transfer的那篇tutorial里很好的表示了loss的写法，想再自己动手试试看看的话可以去看一这篇文档。根据我的经验你大概只需要记住：绝大部分时候你不需要自己写backward，但是比如你要实现一种新的下降算法或是已经提供的计算不能满足的层定义，那再自己去写。</p><p>那么如果自定义一些操作，请遵照一下结构：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomLoss</span>(<span class="title">torch</span>.<span class="title">autograd</span>.<span class="title">Function</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>,*kwargs)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">super</span>(CustomLoss,<span class="keyword">self</span>).__init_<span class="number">_</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(<span class="keyword">self</span>,*kwargs)</span></span><span class="symbol">:</span></span><br><span class="line">        raise NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(<span class="keyword">self</span>,)</span></span></span><br><span class="line">        raise NotImplementedError</span><br></pre></td></tr></table></figure></p><p>按照function继承是要定义backward的，对grad要进行底层实现，基本上只有loss这部分的定义需要费点事。mxnet的定义倒是可以根据符号编程自动推导，符号式编程加自动微分确实很方便，不过sym的调试其实并没有pytorch的动态图来的直观。感觉mxnet在复现上还是更简单快捷粗暴，不过文档不全和有些地方因为更新太快有bug，稍微有点脱了后腿。pytorch这次的更新据说填了不少坑,就我的感受来说，内存不那么容易被多输入Variable的索引跑到炸了，之前的话以Variable对接dataloader在梯度更新后经常要注意取loss[0]，否则直接会加入Variable中的各种参数。据说目前版本解决了这个问题。</p><p>数据集接口没什么太多问题的，dataloader只需要注意cv读和dataloader要求的维度顺序，还有定义最后混合的fusion结构中要构建包含2d ground truth和3d ground truth的样本即可。getitem基本不需要做多少改动，只需要按顺序，3d+2d顺序append，之后索引在3d样本数内读3d，大于部分get 2d样本即可。</p><h2 id="关于版本更新导致的问题"><a href="#关于版本更新导致的问题" class="headerlink" title="关于版本更新导致的问题"></a>关于版本更新导致的问题</h2><p>其实原repo的作者是给出了pretrain的模型的，但是在Stage2阶段是用不了的……我单点打到这一行，发现load的模型是有问题的，这一行定在upsample层上：</p><blockquote><p>self.up2 = nn.Upsample(scale_factor = 2)</p></blockquote><p>事实上upsample需要一个align_corners的参数，在0.4.0之前这个参数应该被直接给了None，导致在0.4.0版本load pretrain的模型后，跑到upsample层的forward时在module的检查时一直报错，会一直报给你检查不到align_corners。再打进内部检验的断点时，发现确实load的模型align_corner是None。如果使用我修改后的pytorch0.4.0兼容的代码train的模型是不存在这个问题的，然而我检查的时候依然没有找到align_corner参数，理论上应该default是False。这可能是底层实现有改动，更底层的部分我就step out没管了。这个大概是版本更新导致的bug，具体有待继续调试验证。如果想看pytorch修改后能用的代码，可以直接跑我fork后的fixed branch，里面已经做了对应的各种修改，在python2.7+ubuntu16.04+pytorch0.4.0下可以正常运行。</p><h2 id="后续工作"><a href="#后续工作" class="headerlink" title="后续工作"></a>后续工作</h2><p>之后会打算对文中内容复现。不过目前遇到一个问题是关节点depth map怎么得到。这个问题目前没找到什么合适的代码或是工具，如果有大佬知道的话希望能邮件或是github issue给我……非常感谢</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/07/16/pytorch-hg-3d%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
