<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Hysteria</title>
    <link>http://yoursite.com/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Keep Calm</description>
    <pubDate>Sat, 15 Sep 2018 02:48:27 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>训练杂谈</title>
      <link>http://yoursite.com/2018/09/15/medicine/</link>
      <guid>http://yoursite.com/2018/09/15/medicine/</guid>
      <pubDate>Sat, 15 Sep 2018 02:39:06 GMT</pubDate>
      <description>
      
        &lt;h2 id=&quot;dl杂谈&quot;&gt;&lt;a href=&quot;#dl杂谈&quot; class=&quot;headerlink&quot; title=&quot;dl杂谈&quot;&gt;&lt;/a&gt;dl杂谈&lt;/h2&gt;&lt;p&gt;其实今年的文章总体有这样一种趋势，除了一些结构上具有开创意义的创新，大家都是小修小补，想发文章就找个差点的baseline飚一飚，比赛就找最好的部件拼一拼开始加trick开始大炼丹。其实都无外乎网络加深提feature再大batch到小batch交替摩擦。loss不降？查查数据，没问题加几层。上大batch加lr再小batch磨一磨，反正有BN这种东西以后大batch满天飞。所以说啥炼丹心得可说还真不容易总结。在这也就是随便一聊。&lt;/p&gt;
&lt;p&gt;不过这倒是可以先谈个问题：你train的真的准么……为啥我问这个问题？你可以自己手写几个层，跟pytorch和tf封装好的层测测输出误差……其实很好奇，为啥pytorch调的cudnn，误差居然比tf大。我有点没搞懂到底谁有问题了。最神奇的还是跟手写的卷积都不一样……如果测试没问题，那还是tensorflow的更准一点，不排除因为浮点精度问题出现了累积误差，但是这确实也挺难搞懂的，回头有时间仔细看看pytorch的卷积怎么写的。&lt;/p&gt;
&lt;h2 id=&quot;training技巧&quot;&gt;&lt;a href=&quot;#training技巧&quot; class=&quot;headerlink&quot; title=&quot;training技巧&quot;&gt;&lt;/a&gt;training技巧&lt;/h2&gt;&lt;p&gt;其实就实验科学的结果来说，这东西真的是个玄学。&lt;br&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="dl杂谈"><a href="#dl杂谈" class="headerlink" title="dl杂谈"></a>dl杂谈</h2><p>其实今年的文章总体有这样一种趋势，除了一些结构上具有开创意义的创新，大家都是小修小补，想发文章就找个差点的baseline飚一飚，比赛就找最好的部件拼一拼开始加trick开始大炼丹。其实都无外乎网络加深提feature再大batch到小batch交替摩擦。loss不降？查查数据，没问题加几层。上大batch加lr再小batch磨一磨，反正有BN这种东西以后大batch满天飞。所以说啥炼丹心得可说还真不容易总结。在这也就是随便一聊。</p><p>不过这倒是可以先谈个问题：你train的真的准么……为啥我问这个问题？你可以自己手写几个层，跟pytorch和tf封装好的层测测输出误差……其实很好奇，为啥pytorch调的cudnn，误差居然比tf大。我有点没搞懂到底谁有问题了。最神奇的还是跟手写的卷积都不一样……如果测试没问题，那还是tensorflow的更准一点，不排除因为浮点精度问题出现了累积误差，但是这确实也挺难搞懂的，回头有时间仔细看看pytorch的卷积怎么写的。</p><h2 id="training技巧"><a href="#training技巧" class="headerlink" title="training技巧"></a>training技巧</h2><p>其实就实验科学的结果来说，这东西真的是个玄学。<br><a id="more"></a><br>下面先讲讲我自己的实验习惯，解释的话可能过段时间再详细开一篇聊聊。 首先我们讲一讲选模型的原则。首先如果需要深层次的特征，抛开任务，提特征的时候有人都会偏爱直接选择resnet之类的比较深比较大的网络，但是很多时候在试验的情况下发现loss一直不降，震荡，不收敛，这时候……先看看数据集或是喂的数据有没有问题才是第一要务。先检查自己prepare的数据是否没问题，比如检测自己的crop是不是有问题，或是在其他的一些数据处理函数上可视化view一下。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果本身喂进网络的数据没有问题，检查一下数据集。如果样本数量本来就不多，可以考虑先用类似的小一点模型，比如resneXt置换成GoogLenet，设置好超参数。</span><br><span class="line">如果在较小的网络上这组超参可以收敛，再把这组参数迁移到大模型上，如果还是不收敛或是还在震荡，可以设optimizer为adam，调小一点<span class="keyword">batch</span>，然后看看能不能在训练中跳出局部极值。跳出去以后可以再选用大<span class="keyword">batch</span> size和之前在小模型上使用的超参继续训。</span><br></pre></td></tr></table></figure><p>说到这可能有入坑小伙伴还没搞懂大batch到底有个啥用，或者batch size这个参数到底影响了什么……其实引入batch normalization后，确实大batch带来的收益更诱人了，目前大量的网络结构也加了相当多的bn层，这样使用大batch有了很好的条件。在这我先简单解释下batch size的一些作用或者意义：</p><ul><li>首先我们谈谈大batch的作用。以sgd举例，事实上sgd大家都知道选一批样本去更新梯度，学这个梯度下降的方向。我们选用大batch，样本更有代表性，因为选择的样本越多，下降肯定越趋于整个数据集收敛应该朝向的方向，所以大batch会更稳定，基本不会在局部震荡， 因为每次参数更新所用到的数据越多，越能代表整体损失函数的梯度，因此梯度精确度更高。另一点是快，而且可以更好利用矩阵计算库里大矩阵乘法的效率，还可以提高显存利用率。</li><li>那小batch自然没有上述的好处，取一个极端例子，如果我们把batch size设为1，这样称为在线学习，每次修正方向以各自样本的梯度方向修正，难以达到收敛。可以理解为因为每次梯度更新只用一个样本，所以后果就是很可能在某一个局部极值点附近震荡……同理可辐射到其他小batch size上，但是同样也有好处，可以在达到一定程度后用来精细的去磨一下你的模型。因为小批量在学习过程中加入了噪声，会有一些正则化效果，但是需要小的学习率保持稳定性，否则还是会跳进局部极值难以自拔</li><li>对于大batch size，达到相同精度需要更多epoch，因为每轮训练中的迭代次数更少。</li></ul><p>所以可以总结下，适当增大batch size好处在于：</p><ul><li>内存利用率提高了。</li><li>对于相同数据量的处理速度更快。</li><li>在一定范围内，一般来说batch size 越大，其确定的下降方向越准，引起训练震荡越小。</li></ul><p>但是盲目增大绝对不行，毕竟首先不是所有实验室都有那么好的设备，batch size上去了，首先也得有足够内存和显存支撑。 另外根据上面提到的要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。主要还有一点，batch size大到一定程度，下降方向已经基本不再变化，加了也没什么用。 所以说本质上还是需要考虑到你的任务到底塞多少合适，另外你的设备到底能怎么撑。一般来说，取2,4,8这么多块卡并行跑，选择一个合适的batch size塞显存就很重要了，因为要考虑显存占用率，你的实验室基友们也不是不跑实验的……不过一般来说，开始训勇敢取个大batch并没啥坏处，有bn撑腰，一切显得美好很多。</p><p>另一方面普遍要动的超参就是学习率了。嗯……这没啥好说的，为了训练稳定自然都愿意选小一点的lr或是先大lr降，不收敛不稳定再换小lr跳出震荡。其他自引入超参，emmmm，仁者见仁智者见智，其实是闻者伤心听者流泪……都是调参血泪史。</p><p>当然了，上面说的一切都要看你的实验室/公司项目组有没有钱，毕竟钱才是科学第一推动力。感谢实验室，感谢以前搭集群的师兄们，真的，实属带善人。（保证我能在核弹水平服务器上钓上一整天的鱼）</p><p>顺带恭喜师兄中best paper。2018年大吉，求下周cvpr讨论别被批成瓜皮。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/09/15/medicine/#disqus_thread</comments>
    </item>
    
    <item>
      <title>反向飞驰</title>
      <link>http://yoursite.com/2018/09/09/run-backward/</link>
      <guid>http://yoursite.com/2018/09/09/run-backward/</guid>
      <pubDate>Sun, 09 Sep 2018 15:32:23 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;最近事情堆积如山，准备cvpr的进一步实验，开始校招的长周期准备。其实投稿大概就是督促自己做点事情，毕竟一直只是实验不带着压力工作效率就不高。&lt;/p&gt;
&lt;p&gt;前途非常迷，今年校招的行情比较迷，看不懂，没有一篇顶会文章算法岗做敲门砖，算法岗很难进大厂，本身我在研究上也不擅长。
        
      
      </description>
      
      <content:encoded><![CDATA[<p>最近事情堆积如山，准备cvpr的进一步实验，开始校招的长周期准备。其实投稿大概就是督促自己做点事情，毕竟一直只是实验不带着压力工作效率就不高。</p><p>前途非常迷，今年校招的行情比较迷，看不懂，没有一篇顶会文章算法岗做敲门砖，算法岗很难进大厂，本身我在研究上也不擅长。准备拿起老本行，准备找开发，负面情绪堆积严重，毕竟和以前赶上好时候的人相比容易心态爆炸，没有比较就没有伤害。</p><p>其实大部分时间我对于成功和开心的定义都比别人简单：</p><ul><li>波澜不惊就算开心</li><li>比普通人过的好一点就算成功</li></ul><p>然而最近基本都是反向飞驰。没有一天安稳，没有一天看到超越平庸的曙光。</p><p>急需调整心态，明天开始扑在framework修改和刷题。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/09/09/run-backward/#disqus_thread</comments>
    </item>
    
    <item>
      <title>教师论</title>
      <link>http://yoursite.com/2018/09/03/%E6%95%99%E5%B8%88%E8%AE%BA/</link>
      <guid>http://yoursite.com/2018/09/03/%E6%95%99%E5%B8%88%E8%AE%BA/</guid>
      <pubDate>Mon, 03 Sep 2018 05:09:52 GMT</pubDate>
      <description>
      
        &lt;p&gt;首先声明，本文纯属虚构，你懂的。&lt;/p&gt;
&lt;h2 id=&quot;初衷&quot;&gt;&lt;a href=&quot;#初衷&quot; class=&quot;headerlink&quot; title=&quot;初衷&quot;&gt;&lt;/a&gt;初衷&lt;/h2&gt;&lt;p&gt;我写这篇文章的初衷很简单，就是我上学这么多年以来，在教师群体中见过的渣滓实在太多。最近又被某些道貌岸然，满嘴胡话的所谓叫大学教师恶心到了。虽然觉得以我的视角定论大多数老师不好，以偏概全着实是一种不好的行为，有管中窥豹之嫌。然而打着人类灵魂工程师的旗号，行败类之实者，也需要遭到口诛笔伐，否则就让奸人占了便宜，犯了错就要挨打，这不应该只适用于学生，或是弱势群体。大概这群蠢货也不会翻墙，所以我就开门见山聊聊这些荒诞事。&lt;/p&gt;
&lt;h2 id=&quot;导火索&quot;&gt;&lt;a href=&quot;#导火索&quot; class=&quot;headerlink&quot; title=&quot;导火索&quot;&gt;&lt;/a&gt;导火索&lt;/h2&gt;&lt;p&gt;要论道貌岸然，满口胡话，某些大学老师确实给我留下了极为深刻的印象。我对有些高中老师的评论最多也就是贪得无厌，误人子弟，吃拿卡要。毕竟读初高中的时候，精力基本都在学习上，不太会考虑一些学业以外的事情。&lt;br&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>首先声明，本文纯属虚构，你懂的。</p><h2 id="初衷"><a href="#初衷" class="headerlink" title="初衷"></a>初衷</h2><p>我写这篇文章的初衷很简单，就是我上学这么多年以来，在教师群体中见过的渣滓实在太多。最近又被某些道貌岸然，满嘴胡话的所谓叫大学教师恶心到了。虽然觉得以我的视角定论大多数老师不好，以偏概全着实是一种不好的行为，有管中窥豹之嫌。然而打着人类灵魂工程师的旗号，行败类之实者，也需要遭到口诛笔伐，否则就让奸人占了便宜，犯了错就要挨打，这不应该只适用于学生，或是弱势群体。大概这群蠢货也不会翻墙，所以我就开门见山聊聊这些荒诞事。</p><h2 id="导火索"><a href="#导火索" class="headerlink" title="导火索"></a>导火索</h2><p>要论道貌岸然，满口胡话，某些大学老师确实给我留下了极为深刻的印象。我对有些高中老师的评论最多也就是贪得无厌，误人子弟，吃拿卡要。毕竟读初高中的时候，精力基本都在学习上，不太会考虑一些学业以外的事情。<br><a id="more"></a><br>但对于某些大学老师，我一般都不吝惜粗鄙之语，因为我能想到的文明词汇确实难以形容他们的极端无耻，对于三观已经基本成型的大学生极尽精神折磨之能事，典型案例确实不胜枚举。陈小武的案件这种被扒出来的毕竟是少数，反正我是觉得做的这么过分的居然能潜伏这么久才被公开也是奇闻一件。但是除了这种罪大恶极的，还有很多在各种细节上打擦边球恶心人的叫兽们。我着实是气不过，觉得是该发声一下了。</p><h2 id="大学残渣"><a href="#大学残渣" class="headerlink" title="大学残渣"></a>大学残渣</h2><p>大学里的某些渣滓，从误人子弟到毁人前程，真的是变着法的败人品。我接触的典型，就不得不点名亲自体验过的某电的通院大教授杨某虎，此君身上充满了各种这些龌龊至极的大学残渣教授的典型问题，上课空谈，什么都不讲，作为教师频繁上课迟到，到了以后开始刻意宣扬自己的威严，然后一阵狂吹，不讲任何具体的东西，讲课逻辑及其混乱，东一榔头西一棒槌，夹带各种私货，动不动就将自己所谓的光荣事迹。更可笑的事，他上课一大半时间都在讲各种没用的东西，到最后一直鼓吹“我的课你要是三节听完，没有搞明白随机过程，那你就是蠢”。这句话当年简直让我笑出猪叫，我到现在还记得当年他的两大笑skr人的场景：叫人上黑板写题，他一口一个你写的不对，被人家质问了不得不认错；指着上节课的java代码说这是matlab还死鸭子嘴硬。这类老师的套路就是我最牛逼，你们这些学生都得听我的，你们干啥都不对，我有绝对权威。我并不认识该虎的研究生，不好评价他对研究生是不是也像王攀先生那个样子，不过在我本科的时候，他确实上课时候大肆宣扬他不让自己的硕士生毕业，处处为难他们的事实，而且露出以此为荣的表情，我不得不承认我当时真的被恶心到了，踹他一脚的冲动到现在也没有消失。他确实代表了很大一部分大学老师的情况：又蠢又菜而且不自知，虽然这有可能要怪在几十年前教育水平确实不行上，但是上课空洞，反而最后赖学生不行，这大概就是个人品行问题了。大学教学的确是属于教师引导，学生自学为主，不过首先，您是不是得确定一下您是不是有引导作用啊？严格和无耻是两码事，可惜有些无耻之徒大概意识不到这个问题。</p><p>杨姓教授其实最搞笑的地方还是在于考试出成绩。据我所知，某电的绝大部分老师都会在考试后半个月左右出成绩。杨叫兽的课程非常有趣，大概12月份考试，拖了两个月左右不出成绩，等到过年前这个王八犊子通知班长说出成绩了，你们班挂xx人（全班百分之六十吧）。不仅蠢，而且坏，过年的时候搅和别人的心情，你大概就知道他是个什么样的人了，而且拖拖拉拉到学生离校，多半也是怂，怕学生报复。我曾经在学校里多次看见他散步，基本都是他一个人带条狗，大概已经名声差到没人理了吧。往届师兄师姐据说没少跟他吵，举报，但是为什么他能一直在某电通院任职教授到现在，我也不是很理解，只能说大学学院里关系网大概真的挺复杂的，这种上课出口就辱骂别的老师不行的人（此虎上课没少直接点名道姓说别的老师水平不行），明显双商欠费，却能在行政上混出点模样，手动滑稽。</p><p>反正不少教研室水都很深，不是动辄博士7年毕业，就是刁难人找工作，安排一堆杂活。其实学校发展不起来，原因很简单，水平不够一方面，很多老师脑子被僵尸吃了是另一个重要因素。不少大学叫兽的目光短浅简直令人惊叹，他们一面以刁难学生为乐，另一面又疯狂push学生，逼学生产出，自己也不提供任何指导作用。</p><p>最奇妙的老师都是出在上课的时候。另一位堪称最恶心人的老师，也是我上课时候接触的，我一直猜测这位狗混子是不是某虎老师的狗(qin)腿(er)子(zi)？虽然这样有点侮辱人格，但是不得不说俩人上课风格如出一辙。空，极端空洞，一门通选理论课上成了吹水课，一般来说能把一节一个半小时的课吹牛逼吹满，我觉得确实也是不太容易。上课基本不讲跟课有关的东西，平均五节课能讲一点，还只会讲跟自己课题相关的一点内容。问题是你长脑子了么？所有人的课题都跟你的课题相关？别的不说，我自己的课题就跟他扯的一点关系都没有。上课从东扯到西，最后一门通选课上课考试出题出的和专业课一样，典型的夹带私货，完全没有作为一个教师的资格和底线。我不求教师能因材施教，在中国那是一种奢侈，但是我们需要但求公平或是底线，私自把一门理论课的侧重点带歪了不说，还最后各种蓄意往自己的方向引导，如果你没有带好一门理论课的能力，请放过这门科学，理论不是你应用的后花园，不是所有人都得跟你一块沉浸在你的世界，自大又蠢，毫无底线，作为一个教师对教学的基本准则都无法理解和遵守，完全不重视科学本质和课堂应该讲授的内容，自我感觉极度良好，不得不说这也是我见过的最恶心的老师之一了，大概在我求学期间都排的上号，和虎老师各有千秋，这位更喜欢装的道貌岸然，不像某虎，虎老师是赤裸裸的小人，这位就可以说是伪君子，道貌岸然届冉冉升起的新星。</p><p>不得不说，我也确实见过不少好老师，比如某吴姓老师这样的人，基本可以说是教师人品的楷模。但是其实变态老师确实不少，以刁难学生为乐，甩锅，不辅导，只会不停的push，让学生写本子，在目前的中国高校内，比例高的已经可以说是病态了。我其实挺希望能整治的，但是目前没看到什么希望，毕竟感觉不到学校的以人为本，大部分学校学院基本都是保老师而把学生诉求当麻烦的。就当是空谈好了，只是想简单描述这些病态的现象。</p><p>本文纯属虚构，你懂的，请勿对号入组。手动没有狗头。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/09/03/%E6%95%99%E5%B8%88%E8%AE%BA/#disqus_thread</comments>
    </item>
    
    <item>
      <title>pytorch升级和imread区别</title>
      <link>http://yoursite.com/2018/09/01/iocv/</link>
      <guid>http://yoursite.com/2018/09/01/iocv/</guid>
      <pubDate>Sat, 01 Sep 2018 08:05:33 GMT</pubDate>
      <description>
      
        &lt;p&gt;前段时间写了一版multiposenet的结构，调试的时候发现了几个问题。&lt;/p&gt;
&lt;p&gt;首先是pytorch0.4.0到0.4.1的更新。这个版本的更新里引入了一个比较有用的降采样函数，torch.nn.Functional.interpolate。文档上介绍的也很明确，调用时可以指定升/降采样的size或者一个尺度因子scale_factor。之前其实一直没有一个官方给出的降采样函数或是层，原来融合多个size每次都要复用手写的层，某些时候还不知道对不对的上别人文章的降采样方法……这回添加了一个官方的降采样方法，这样可能细节上可能大家都能统一一点，实验代码也好写一点或是复现一点，而且可以下采样到任意size或是scale，避免了很多方法实现上的微妙区别。load模型的时候跟0.4.0没什么区别，不像0.3.0升0.4.0时由于upsample变动导致我大量模型load不能的囧境。&lt;/p&gt;
&lt;p&gt;另外就是关于skimage.io.imread和cv2.imread的一个细节问题，读灰度图时，skimage的读取会读出2通道，而opencv中不添加灰度的flag的时候传入会默认处理成三通道。一开始我随手拿io.imread读了原图，原灰度图是这个样子：&lt;br&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/mw690/005uXRWzly1fuu5q3psxhj30bl09076u.jpg&quot; alt=&quot;avatar&quot;&gt;&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>前段时间写了一版multiposenet的结构，调试的时候发现了几个问题。</p><p>首先是pytorch0.4.0到0.4.1的更新。这个版本的更新里引入了一个比较有用的降采样函数，torch.nn.Functional.interpolate。文档上介绍的也很明确，调用时可以指定升/降采样的size或者一个尺度因子scale_factor。之前其实一直没有一个官方给出的降采样函数或是层，原来融合多个size每次都要复用手写的层，某些时候还不知道对不对的上别人文章的降采样方法……这回添加了一个官方的降采样方法，这样可能细节上可能大家都能统一一点，实验代码也好写一点或是复现一点，而且可以下采样到任意size或是scale，避免了很多方法实现上的微妙区别。load模型的时候跟0.4.0没什么区别，不像0.3.0升0.4.0时由于upsample变动导致我大量模型load不能的囧境。</p><p>另外就是关于skimage.io.imread和cv2.imread的一个细节问题，读灰度图时，skimage的读取会读出2通道，而opencv中不添加灰度的flag的时候传入会默认处理成三通道。一开始我随手拿io.imread读了原图，原灰度图是这个样子：<br><img src="http://wx1.sinaimg.cn/mw690/005uXRWzly1fuu5q3psxhj30bl09076u.jpg" alt="avatar"></p><a id="more"></a><p>训练跑到一半的时候突然发现tensor运算的时候左右值维度不匹配，才发现了这个细节问题……之前一直都是用cv2.imread,也不会往里传grey的相关参数，直接默认读出三通道，但是灰度图直接拿io.imread调用时会出现shape只有(width,height)两位的问题。去翻了翻skimage的源码，as_grey参数已经deprecated了，其中有这么一段处理：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="selector-tag">img</span><span class="selector-class">.ndim</span> &gt; <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="selector-tag">img</span><span class="selector-class">.shape</span>[-<span class="number">1</span>] not <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">4</span>) and <span class="selector-tag">img</span><span class="selector-class">.shape</span>[-<span class="number">3</span>] <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">4</span>):</span><br><span class="line">        <span class="selector-tag">img</span> = np.swapaxes(<span class="selector-tag">img</span>, -<span class="number">1</span>, -<span class="number">3</span>)</span><br><span class="line">        <span class="selector-tag">img</span> = np.swapaxes(<span class="selector-tag">img</span>, -<span class="number">2</span>, -<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> as_gray:</span><br><span class="line">        <span class="selector-tag">img</span> = rgb2gray(img)</span><br></pre></td></tr></table></figure></p><p>内部在ndim大于3的情况下，flag设为True也只是会粗暴的直接转化，ndim为2的时候他就直接读出(height,width)维的数组了，所以说这个确实……cv的读取就避免了这个问题。看来还好以前都是直接调cv.imread，这次因为要调transform顺手调了io，以后还是得注意数据喂进去到底是啥……以前也出现过喂错东西跑瞎实验的情况，毕竟数据驱动型的工作，数据的纯净度、形式组织还是至关重要的，得涨点记性。</p><p>另外就是multiposenet的子网络问题，目前我也不知道作者在test-dev上的统一size到底用了多大。而且按照原文中的结构，不给出一些细节，最后的ground truth和heatmap的size是绝对不匹配的，目前我强制采样到了256x256，有理解的朋友可以交流一下，代码repo在这：<a href="https://github.com/IcewineChen/pytorch-MultiPoseNet" target="_blank" rel="noopener">https://github.com/IcewineChen/pytorch-MultiPoseNet</a></p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/09/01/iocv/#disqus_thread</comments>
    </item>
    
    <item>
      <title>新评论gitalk系统踩坑</title>
      <link>http://yoursite.com/2018/08/30/gitment%E2%80%94%E2%80%94config/</link>
      <guid>http://yoursite.com/2018/08/30/gitment%E2%80%94%E2%80%94config/</guid>
      <pubDate>Thu, 30 Aug 2018 15:39:58 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;新评论系统踩坑经历&quot;&gt;&lt;a href=&quot;#新评论系统踩坑经历&quot; class=&quot;headerlink&quot; title=&quot;新评论系统踩坑经历&quot;&gt;&lt;/a&gt;新评论系统踩坑经历&lt;/h1&gt;&lt;h2 id=&quot;选择过程&quot;&gt;&lt;a href=&quot;#选择过程&quot; class=&quot;headerlink&quot; title=&quot;选择过程&quot;&gt;&lt;/a&gt;选择过程&lt;/h2&gt;&lt;p&gt;现在博客已经改成valine了，对一些不常用github的访客来说，评论更简单，如果想用gitalk，可以参照本文。&lt;/p&gt;
&lt;p&gt;网易云跟帖和多说都挂掉了，所以急需一款新的比较好用的跟帖评论工具。比较了下面几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hexo官方文档里的扩展：disqus，因为墙你懂得&lt;/li&gt;
&lt;li&gt;来必力 同样存在加载慢的问题&lt;/li&gt;
&lt;li&gt;gitalk 看起来不错，依托github issue, 支持markdown&lt;/li&gt;
&lt;li&gt;hypercomments，唯一缺点不支持markdown&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;好吧那就选gitalk吧&lt;/p&gt;
&lt;h2 id=&quot;实际工作&quot;&gt;&lt;a href=&quot;#实际工作&quot; class=&quot;headerlink&quot; title=&quot;实际工作&quot;&gt;&lt;/a&gt;实际工作&lt;/h2&gt;&lt;p&gt;其实按照网上多如牛毛的添加gitalk教程来就行，我随手在这贴一个：&lt;a href=&quot;https://www.jianshu.com/p/9be29ed2f4b7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.jianshu.com/p/9be29ed2f4b7&lt;/a&gt; ，感谢这位的分享，虽然我大概看的不是他的分享……只是表达一下随手就能搜出一斤的情况。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那说好的坑呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;别急……有俩坑。&lt;br&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="新评论系统踩坑经历"><a href="#新评论系统踩坑经历" class="headerlink" title="新评论系统踩坑经历"></a>新评论系统踩坑经历</h1><h2 id="选择过程"><a href="#选择过程" class="headerlink" title="选择过程"></a>选择过程</h2><p>现在博客已经改成valine了，对一些不常用github的访客来说，评论更简单，如果想用gitalk，可以参照本文。</p><p>网易云跟帖和多说都挂掉了，所以急需一款新的比较好用的跟帖评论工具。比较了下面几种：</p><ul><li>hexo官方文档里的扩展：disqus，因为墙你懂得</li><li>来必力 同样存在加载慢的问题</li><li>gitalk 看起来不错，依托github issue, 支持markdown</li><li>hypercomments，唯一缺点不支持markdown</li></ul><p>好吧那就选gitalk吧</p><h2 id="实际工作"><a href="#实际工作" class="headerlink" title="实际工作"></a>实际工作</h2><p>其实按照网上多如牛毛的添加gitalk教程来就行，我随手在这贴一个：<a href="https://www.jianshu.com/p/9be29ed2f4b7" target="_blank" rel="noopener">https://www.jianshu.com/p/9be29ed2f4b7</a> ，感谢这位的分享，虽然我大概看的不是他的分享……只是表达一下随手就能搜出一斤的情况。</p><blockquote><p>那说好的坑呢？</p></blockquote><p>别急……有俩坑。<br><a id="more"></a><br>第一个坑在github应用创建的时候，如果你绑定了自己的个性化域名，homepage url和回调url一定填自己绑定后的域名。这个我开始绑定的github.io，回调就报错。</p><p>第二个坑就出在网上花花绿绿不同教程上了。主要是gitalk配置字段的问题。不论你选择哪一种方法，都会有在主题配置文件添加字段的选项，如下：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gitalk</span></span><br><span class="line"><span class="attr">gitalk:</span> </span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  clientID:</span> <span class="string">'your clientID'</span>    </span><br><span class="line"><span class="attr">  clientSecret:</span> <span class="string">'your clientSecret'</span>   </span><br><span class="line"><span class="attr">  repo:</span> <span class="string">Blog_comments</span>    </span><br><span class="line"><span class="attr">  owner:</span> <span class="string">erbiduo</span>   </span><br><span class="line"><span class="attr">  admin:</span> <span class="string">erbiduo</span></span><br><span class="line"><span class="attr">  distractionFreeMode:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">gitalk:</span><br><span class="line">  enable: <span class="literal">true</span></span><br><span class="line">  githubID: github帐号  # 例：asdfv1929   </span><br><span class="line">  repo: 仓库名称   # 例：asdfv1929.github.io</span><br><span class="line">  ClientID:<span class="built_in"> Client </span>ID</span><br><span class="line">  ClientSecret:<span class="built_in"> Client </span>Secret</span><br><span class="line">  adminUser: github帐号 #指定可初始化评论账户</span><br><span class="line">  distractionFreeMode: <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>这是我在网上找的两个版本的主题文件配置内容，你猜哪个是对的？</p><p>这就需要看你在themes/next/layout/_third-party/comments/gitalk.swig内的字段怎么写的了，swig文件添加进去的内容：<br><figure class="highlight django"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">if</span></span> page.comments &amp;&amp; theme.gitalk.enable %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"https://unpkg.com/gitalk/dist/gitalk.css"</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://unpkg.com/gitalk/dist/gitalk.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml">   <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="undefined"></span></span></span><br><span class="line"><span class="xml">        var gitalk = new Gitalk(&#123;</span></span><br><span class="line"><span class="xml">          clientID: '</span><span class="template-variable">&#123;&#123; theme.gitalk.ClientID &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          clientSecret: '</span><span class="template-variable">&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          repo: '</span><span class="template-variable">&#123;&#123; theme.gitalk.repo &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          owner: '</span><span class="template-variable">&#123;&#123; theme.gitalk.githubID &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          admin: ['</span><span class="template-variable">&#123;&#123; theme.gitalk.adminUser &#125;&#125;</span><span class="xml">'],</span></span><br><span class="line"><span class="xml">          id: location.pathname,</span></span><br><span class="line"><span class="xml">          distractionFreeMode: '</span><span class="template-variable">&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;</span><span class="xml">'</span></span><br><span class="line"><span class="xml">        &#125;)</span></span><br><span class="line"><span class="xml">        gitalk.render('gitalk-container')           </span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="xml"></span></span><br></pre></td></tr></table></figure></p><p>很明显，如果在部署的时候解析你主题文件的配置，字段里Gitalk对象肯定要和配置文件里字段一致，也就是说你的配置文件里gitalk下其他字段要跟Gitalk对象内的字段一致，gitalk.ClientID对应在主题配置文件下的就是ClientID字段，owner:gitalk.githubID和主题配置下githubID字段要这样一一对应，我按照某些教程搭建的时候就出了问题，调试了一下找到了这俩坑。其他的基本就按教程配置就行，最后注意swig中字段和theme下的config.yml一致就可以。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/08/30/gitment%E2%80%94%E2%80%94config/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
