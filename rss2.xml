<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Hysteria</title>
    <link>https://icewinechen.com/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Keep Alive</description>
    <pubDate>Mon, 24 Sep 2018 12:26:40 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>中秋快乐</title>
      <link>https://icewinechen.com/2018/09/23/photo/</link>
      <guid>https://icewinechen.com/2018/09/23/photo/</guid>
      <pubDate>Sun, 23 Sep 2018 12:37:32 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;大学以后头一次在家里过中秋，祝大家中秋快乐啊 =-= 千里共婵娟&lt;/p&gt;

        
      
      </description>
      
      <content:encoded><![CDATA[<p>大学以后头一次在家里过中秋，祝大家中秋快乐啊 =-= 千里共婵娟</p>]]></content:encoded>
      
      <comments>https://icewinechen.com/2018/09/23/photo/#disqus_thread</comments>
    </item>
    
    <item>
      <title>训练杂谈</title>
      <link>https://icewinechen.com/2018/09/15/medicine/</link>
      <guid>https://icewinechen.com/2018/09/15/medicine/</guid>
      <pubDate>Sat, 15 Sep 2018 02:39:06 GMT</pubDate>
      <description>
      
        &lt;h2 id=&quot;dl杂谈&quot;&gt;&lt;a href=&quot;#dl杂谈&quot; class=&quot;headerlink&quot; title=&quot;dl杂谈&quot;&gt;&lt;/a&gt;dl杂谈&lt;/h2&gt;&lt;p&gt;其实今年的文章总体有这样一种趋势，除了一些结构上具有开创意义的创新，大家都是小修小补，想发文章就找个差点的baseline飚一飚，比赛就找最好的部件拼一拼开始加trick开始大炼丹。其实都无外乎网络加深提feature再大batch到小batch交替摩擦。loss不降？查查数据，没问题加几层。上大batch加lr再小batch磨一磨，反正有BN这种东西以后大batch满天飞。所以说啥炼丹心得可说还真不容易总结。在这也就是随便一聊。&lt;/p&gt;
&lt;p&gt;不过这倒是可以先谈个问题：你train的真的准么……为啥我问这个问题？你可以自己手写几个层，跟pytorch和tf封装好的层测测输出误差……其实很好奇，为啥pytorch调的cudnn，误差居然比tf大。我有点没搞懂到底谁有问题了。最神奇的还是跟手写的卷积都不一样……如果测试没问题，那还是tensorflow的更准一点，不排除因为浮点精度问题出现了累积误差，但是这确实也挺难搞懂的，回头有时间仔细看看pytorch的卷积怎么写的。&lt;/p&gt;
&lt;h2 id=&quot;training技巧&quot;&gt;&lt;a href=&quot;#training技巧&quot; class=&quot;headerlink&quot; title=&quot;training技巧&quot;&gt;&lt;/a&gt;training技巧&lt;/h2&gt;&lt;p&gt;其实就实验科学的结果来说，这东西真的是个玄学。&lt;br&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="dl杂谈"><a href="#dl杂谈" class="headerlink" title="dl杂谈"></a>dl杂谈</h2><p>其实今年的文章总体有这样一种趋势，除了一些结构上具有开创意义的创新，大家都是小修小补，想发文章就找个差点的baseline飚一飚，比赛就找最好的部件拼一拼开始加trick开始大炼丹。其实都无外乎网络加深提feature再大batch到小batch交替摩擦。loss不降？查查数据，没问题加几层。上大batch加lr再小batch磨一磨，反正有BN这种东西以后大batch满天飞。所以说啥炼丹心得可说还真不容易总结。在这也就是随便一聊。</p><p>不过这倒是可以先谈个问题：你train的真的准么……为啥我问这个问题？你可以自己手写几个层，跟pytorch和tf封装好的层测测输出误差……其实很好奇，为啥pytorch调的cudnn，误差居然比tf大。我有点没搞懂到底谁有问题了。最神奇的还是跟手写的卷积都不一样……如果测试没问题，那还是tensorflow的更准一点，不排除因为浮点精度问题出现了累积误差，但是这确实也挺难搞懂的，回头有时间仔细看看pytorch的卷积怎么写的。</p><h2 id="training技巧"><a href="#training技巧" class="headerlink" title="training技巧"></a>training技巧</h2><p>其实就实验科学的结果来说，这东西真的是个玄学。<br><a id="more"></a><br>下面先讲讲我自己的实验习惯，解释的话可能过段时间再详细开一篇聊聊。 首先我们讲一讲选模型的原则。首先如果需要深层次的特征，抛开任务，提特征的时候有人都会偏爱直接选择resnet之类的比较深比较大的网络，但是很多时候在试验的情况下发现loss一直不降，震荡，不收敛，这时候……先看看数据集或是喂的数据有没有问题才是第一要务。先检查自己prepare的数据是否没问题，比如检测自己的crop是不是有问题，或是在其他的一些数据处理函数上可视化view一下。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果本身喂进网络的数据没有问题，检查一下数据集。如果样本数量本来就不多，可以考虑先用类似的小一点模型，比如resneXt置换成GoogLenet，设置好超参数。</span><br><span class="line">如果在较小的网络上这组超参可以收敛，再把这组参数迁移到大模型上，如果还是不收敛或是还在震荡，可以设optimizer为adam，调小一点<span class="keyword">batch</span>，然后看看能不能在训练中跳出局部极值。跳出去以后可以再选用大<span class="keyword">batch</span> size和之前在小模型上使用的超参继续训。</span><br></pre></td></tr></table></figure><p>说到这可能有入坑小伙伴还没搞懂大batch到底有个啥用，或者batch size这个参数到底影响了什么……其实引入batch normalization后，确实大batch带来的收益更诱人了，目前大量的网络结构也加了相当多的bn层，这样使用大batch有了很好的条件。在这我先简单解释下batch size的一些作用或者意义：</p><ul><li>首先我们谈谈大batch的作用。以sgd举例，事实上sgd大家都知道选一批样本去更新梯度，学这个梯度下降的方向。我们选用大batch，样本更有代表性，因为选择的样本越多，下降肯定越趋于整个数据集收敛应该朝向的方向，所以大batch会更稳定，基本不会在局部震荡， 因为每次参数更新所用到的数据越多，越能代表整体损失函数的梯度，因此梯度精确度更高。另一点是快，而且可以更好利用矩阵计算库里大矩阵乘法的效率，还可以提高显存利用率。</li><li>那小batch自然没有上述的好处，取一个极端例子，如果我们把batch size设为1，这样称为在线学习，每次修正方向以各自样本的梯度方向修正，难以达到收敛。可以理解为因为每次梯度更新只用一个样本，所以后果就是很可能在某一个局部极值点附近震荡……同理可辐射到其他小batch size上，但是同样也有好处，可以在达到一定程度后用来精细的去磨一下你的模型。因为小批量在学习过程中加入了噪声，会有一些正则化效果，但是需要小的学习率保持稳定性，否则还是会跳进局部极值难以自拔</li><li>对于大batch size，达到相同精度需要更多epoch，因为每轮训练中的迭代次数更少。</li></ul><p>所以可以总结下，适当增大batch size好处在于：</p><ul><li>内存利用率提高了。</li><li>对于相同数据量的处理速度更快。</li><li>在一定范围内，一般来说batch size 越大，其确定的下降方向越准，引起训练震荡越小。</li></ul><p>但是盲目增大绝对不行，毕竟首先不是所有实验室都有那么好的设备，batch size上去了，首先也得有足够内存和显存支撑。 另外根据上面提到的要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。主要还有一点，batch size大到一定程度，下降方向已经基本不再变化，加了也没什么用。 所以说本质上还是需要考虑到你的任务到底塞多少合适，另外你的设备到底能怎么撑。一般来说，取2,4,8这么多块卡并行跑，选择一个合适的batch size塞显存就很重要了，因为要考虑显存占用率，你的实验室基友们也不是不跑实验的……不过一般来说，开始训勇敢取个大batch并没啥坏处，有bn撑腰，一切显得美好很多。</p><p>另一方面普遍要动的超参就是学习率了。嗯……这没啥好说的，为了训练稳定自然都愿意选小一点的lr或是先大lr降，不收敛不稳定再换小lr跳出震荡。其他自引入超参，emmmm，仁者见仁智者见智，其实是闻者伤心听者流泪……都是调参血泪史。</p><p>当然了，上面说的一切都要看你的实验室/公司项目组有没有钱，毕竟钱才是科学第一推动力。感谢以前搭集群的师兄们，真的，实属带善人。</p>]]></content:encoded>
      
      <comments>https://icewinechen.com/2018/09/15/medicine/#disqus_thread</comments>
    </item>
    
    <item>
      <title>反向飞驰</title>
      <link>https://icewinechen.com/2018/09/09/run-backward/</link>
      <guid>https://icewinechen.com/2018/09/09/run-backward/</guid>
      <pubDate>Sun, 09 Sep 2018 15:32:23 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;最近事情堆积如山，准备cvpr的进一步实验，开始校招的长周期准备。其实投稿大概就是督促自己做点事情，毕竟一直只是实验不带着压力工作效率就不高。&lt;/p&gt;
&lt;p&gt;前途非常迷，今年校招的行情比较迷，看不懂，没有一篇顶会文章算法岗做敲门砖，算法岗很难进大厂，本身我在研究上也不擅长。
        
      
      </description>
      
      <content:encoded><![CDATA[<p>最近事情堆积如山，准备cvpr的进一步实验，开始校招的长周期准备。其实投稿大概就是督促自己做点事情，毕竟一直只是实验不带着压力工作效率就不高。</p><p>前途非常迷，今年校招的行情比较迷，看不懂，没有一篇顶会文章算法岗做敲门砖，算法岗很难进大厂，本身我在研究上也不擅长。准备拿起老本行，准备找开发，负面情绪堆积严重，毕竟和以前赶上好时候的人相比容易心态爆炸，没有比较就没有伤害。</p><p>其实大部分时间我对于成功和开心的定义都比别人简单：</p><ul><li>波澜不惊就算开心</li><li>比普通人过的好一点就算成功</li></ul><p>然而最近基本都是反向飞驰。没有一天安稳，没有一天看到超越平庸的曙光。</p><p>急需调整心态，明天开始扑在framework修改和刷题。</p>]]></content:encoded>
      
      <comments>https://icewinechen.com/2018/09/09/run-backward/#disqus_thread</comments>
    </item>
    
    <item>
      <title>pytorch升级和imread区别</title>
      <link>https://icewinechen.com/2018/09/01/iocv/</link>
      <guid>https://icewinechen.com/2018/09/01/iocv/</guid>
      <pubDate>Sat, 01 Sep 2018 08:05:33 GMT</pubDate>
      <description>
      
        &lt;p&gt;前段时间写了一版multiposenet的结构，调试的时候发现了几个问题。&lt;/p&gt;
&lt;p&gt;首先是pytorch0.4.0到0.4.1的更新。这个版本的更新里引入了一个比较有用的降采样函数，torch.nn.Functional.interpolate。文档上介绍的也很明确，调用时可以指定升/降采样的size或者一个尺度因子scale_factor。之前其实一直没有一个官方给出的降采样函数或是层，原来融合多个size每次都要复用手写的层，某些时候还不知道对不对的上别人文章的降采样方法……这回添加了一个官方的降采样方法，这样可能细节上可能大家都能统一一点，实验代码也好写一点或是复现一点，而且可以下采样到任意size或是scale，避免了很多方法实现上的微妙区别。load模型的时候跟0.4.0没什么区别，不像0.3.0升0.4.0时由于upsample变动导致我大量模型load不能的囧境。&lt;/p&gt;
&lt;p&gt;另外就是关于skimage.io.imread和cv2.imread的一个细节问题，读灰度图时，skimage的读取会读出2通道，而opencv中不添加灰度的flag的时候传入会默认处理成三通道。一开始我随手拿io.imread读了原图，原灰度图是这个样子：&lt;br&gt;&lt;img src=&quot;http://wx1.sinaimg.cn/mw690/005uXRWzly1fuu5q3psxhj30bl09076u.jpg&quot; alt=&quot;avatar&quot;&gt;&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>前段时间写了一版multiposenet的结构，调试的时候发现了几个问题。</p><p>首先是pytorch0.4.0到0.4.1的更新。这个版本的更新里引入了一个比较有用的降采样函数，torch.nn.Functional.interpolate。文档上介绍的也很明确，调用时可以指定升/降采样的size或者一个尺度因子scale_factor。之前其实一直没有一个官方给出的降采样函数或是层，原来融合多个size每次都要复用手写的层，某些时候还不知道对不对的上别人文章的降采样方法……这回添加了一个官方的降采样方法，这样可能细节上可能大家都能统一一点，实验代码也好写一点或是复现一点，而且可以下采样到任意size或是scale，避免了很多方法实现上的微妙区别。load模型的时候跟0.4.0没什么区别，不像0.3.0升0.4.0时由于upsample变动导致我大量模型load不能的囧境。</p><p>另外就是关于skimage.io.imread和cv2.imread的一个细节问题，读灰度图时，skimage的读取会读出2通道，而opencv中不添加灰度的flag的时候传入会默认处理成三通道。一开始我随手拿io.imread读了原图，原灰度图是这个样子：<br><img src="http://wx1.sinaimg.cn/mw690/005uXRWzly1fuu5q3psxhj30bl09076u.jpg" alt="avatar"></p><a id="more"></a><p>训练跑到一半的时候突然发现tensor运算的时候左右值维度不匹配，才发现了这个细节问题……之前一直都是用cv2.imread,也不会往里传grey的相关参数，直接默认读出三通道，但是灰度图直接拿io.imread调用时会出现shape只有(width,height)两位的问题。去翻了翻skimage的源码，as_grey参数已经deprecated了，其中有这么一段处理：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="selector-tag">img</span><span class="selector-class">.ndim</span> &gt; <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="selector-tag">img</span><span class="selector-class">.shape</span>[-<span class="number">1</span>] not <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">4</span>) and <span class="selector-tag">img</span><span class="selector-class">.shape</span>[-<span class="number">3</span>] <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">4</span>):</span><br><span class="line">        <span class="selector-tag">img</span> = np.swapaxes(<span class="selector-tag">img</span>, -<span class="number">1</span>, -<span class="number">3</span>)</span><br><span class="line">        <span class="selector-tag">img</span> = np.swapaxes(<span class="selector-tag">img</span>, -<span class="number">2</span>, -<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> as_gray:</span><br><span class="line">        <span class="selector-tag">img</span> = rgb2gray(img)</span><br></pre></td></tr></table></figure></p><p>内部在ndim大于3的情况下，flag设为True也只是会粗暴的直接转化，ndim为2的时候他就直接读出(height,width)维的数组了，所以说这个确实……cv的读取就避免了这个问题。看来还好以前都是直接调cv.imread，这次因为要调transform顺手调了io，以后还是得注意数据喂进去到底是啥……以前也出现过喂错东西跑瞎实验的情况，毕竟数据驱动型的工作，数据的纯净度、形式组织还是至关重要的，得涨点记性。</p><p>另外就是multiposenet的子网络问题，目前我也不知道作者在test-dev上的统一size到底用了多大。而且按照原文中的结构，不给出一些细节，最后的ground truth和heatmap的size是绝对不匹配的，目前我强制采样到了256x256，有理解的朋友可以交流一下，代码repo在这：<a href="https://github.com/IcewineChen/pytorch-MultiPoseNet" target="_blank" rel="noopener">https://github.com/IcewineChen/pytorch-MultiPoseNet</a></p>]]></content:encoded>
      
      <comments>https://icewinechen.com/2018/09/01/iocv/#disqus_thread</comments>
    </item>
    
    <item>
      <title>新评论gitalk系统踩坑</title>
      <link>https://icewinechen.com/2018/08/30/gitment%E2%80%94%E2%80%94config/</link>
      <guid>https://icewinechen.com/2018/08/30/gitment%E2%80%94%E2%80%94config/</guid>
      <pubDate>Thu, 30 Aug 2018 15:39:58 GMT</pubDate>
      <description>
      
        &lt;p&gt;放弃issue形式的评论了。已经在新blog启用valine了，issue有更新会比较烦人。&lt;/p&gt;
&lt;h2 id=&quot;选择过程&quot;&gt;&lt;a href=&quot;#选择过程&quot; class=&quot;headerlink&quot; title=&quot;选择过程&quot;&gt;&lt;/a&gt;选择过程&lt;/h2&gt;&lt;p&gt;现在博客已经改成valine了，对一些不常用github的访客来说，评论更简单，如果想用gitalk，可以参照本文。&lt;/p&gt;
&lt;p&gt;网易云跟帖和多说都挂掉了，所以急需一款新的比较好用的跟帖评论工具。比较了下面几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hexo官方文档里的扩展：disqus，因为墙你懂得&lt;/li&gt;
&lt;li&gt;来必力 同样存在加载慢的问题&lt;/li&gt;
&lt;li&gt;gitalk 看起来不错，依托github issue, 支持markdown&lt;/li&gt;
&lt;li&gt;hypercomments，唯一缺点不支持markdown&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;好吧那就选gitalk吧&lt;/p&gt;
&lt;h2 id=&quot;实际工作&quot;&gt;&lt;a href=&quot;#实际工作&quot; class=&quot;headerlink&quot; title=&quot;实际工作&quot;&gt;&lt;/a&gt;实际工作&lt;/h2&gt;&lt;p&gt;其实按照网上多如牛毛的添加gitalk教程来就行，我随手在这贴一个：&lt;a href=&quot;https://www.jianshu.com/p/9be29ed2f4b7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.jianshu.com/p/9be29ed2f4b7&lt;/a&gt; ，感谢这位的分享，虽然我大概看的不是他的分享……只是表达一下随手就能搜出一斤的情况。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那说好的坑呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;别急……有俩坑。&lt;br&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>放弃issue形式的评论了。已经在新blog启用valine了，issue有更新会比较烦人。</p><h2 id="选择过程"><a href="#选择过程" class="headerlink" title="选择过程"></a>选择过程</h2><p>现在博客已经改成valine了，对一些不常用github的访客来说，评论更简单，如果想用gitalk，可以参照本文。</p><p>网易云跟帖和多说都挂掉了，所以急需一款新的比较好用的跟帖评论工具。比较了下面几种：</p><ul><li>hexo官方文档里的扩展：disqus，因为墙你懂得</li><li>来必力 同样存在加载慢的问题</li><li>gitalk 看起来不错，依托github issue, 支持markdown</li><li>hypercomments，唯一缺点不支持markdown</li></ul><p>好吧那就选gitalk吧</p><h2 id="实际工作"><a href="#实际工作" class="headerlink" title="实际工作"></a>实际工作</h2><p>其实按照网上多如牛毛的添加gitalk教程来就行，我随手在这贴一个：<a href="https://www.jianshu.com/p/9be29ed2f4b7" target="_blank" rel="noopener">https://www.jianshu.com/p/9be29ed2f4b7</a> ，感谢这位的分享，虽然我大概看的不是他的分享……只是表达一下随手就能搜出一斤的情况。</p><blockquote><p>那说好的坑呢？</p></blockquote><p>别急……有俩坑。<br><a id="more"></a><br>第一个坑在github应用创建的时候，如果你绑定了自己的个性化域名，homepage url和回调url一定填自己绑定后的域名。这个我开始绑定的github.io，回调就报错。</p><p>第二个坑就出在网上花花绿绿不同教程上了。主要是gitalk配置字段的问题。不论你选择哪一种方法，都会有在主题配置文件添加字段的选项，如下：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Gitalk</span></span><br><span class="line"><span class="attr">gitalk:</span> </span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  clientID:</span> <span class="string">'your clientID'</span>    </span><br><span class="line"><span class="attr">  clientSecret:</span> <span class="string">'your clientSecret'</span>   </span><br><span class="line"><span class="attr">  repo:</span> <span class="string">Blog_comments</span>    </span><br><span class="line"><span class="attr">  owner:</span> <span class="string">erbiduo</span>   </span><br><span class="line"><span class="attr">  admin:</span> <span class="string">erbiduo</span></span><br><span class="line"><span class="attr">  distractionFreeMode:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">gitalk:</span><br><span class="line">  enable: <span class="literal">true</span></span><br><span class="line">  githubID: github帐号  # 例：asdfv1929   </span><br><span class="line">  repo: 仓库名称   # 例：asdfv1929.github.io</span><br><span class="line">  ClientID:<span class="built_in"> Client </span>ID</span><br><span class="line">  ClientSecret:<span class="built_in"> Client </span>Secret</span><br><span class="line">  adminUser: github帐号 #指定可初始化评论账户</span><br><span class="line">  distractionFreeMode: <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>这是我在网上找的两个版本的主题文件配置内容，你猜哪个是对的？</p><p>这就需要看你在themes/next/layout/_third-party/comments/gitalk.swig内的字段怎么写的了，swig文件添加进去的内容：<br><figure class="highlight django"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">if</span></span> page.comments &amp;&amp; theme.gitalk.enable %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"https://unpkg.com/gitalk/dist/gitalk.css"</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://unpkg.com/gitalk/dist/gitalk.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml">   <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="undefined"></span></span></span><br><span class="line"><span class="xml">        var gitalk = new Gitalk(&#123;</span></span><br><span class="line"><span class="xml">          clientID: '</span><span class="template-variable">&#123;&#123; theme.gitalk.ClientID &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          clientSecret: '</span><span class="template-variable">&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          repo: '</span><span class="template-variable">&#123;&#123; theme.gitalk.repo &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          owner: '</span><span class="template-variable">&#123;&#123; theme.gitalk.githubID &#125;&#125;</span><span class="xml">',</span></span><br><span class="line"><span class="xml">          admin: ['</span><span class="template-variable">&#123;&#123; theme.gitalk.adminUser &#125;&#125;</span><span class="xml">'],</span></span><br><span class="line"><span class="xml">          id: location.pathname,</span></span><br><span class="line"><span class="xml">          distractionFreeMode: '</span><span class="template-variable">&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;</span><span class="xml">'</span></span><br><span class="line"><span class="xml">        &#125;)</span></span><br><span class="line"><span class="xml">        gitalk.render('gitalk-container')           </span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="xml"></span></span><br></pre></td></tr></table></figure></p><p>很明显，如果在部署的时候解析你主题文件的配置，模板字段里Gitalk对象肯定要和配置文件里字段一致，也就是说你的配置文件里gitalk下其他字段要跟Gitalk对象内的字段一致，gitalk.ClientID对应在主题配置文件下的就是ClientID字段，owner:gitalk.githubID和主题配置下githubID字段要这样一一对应，我按照某些教程搭建的时候就出了问题，调试了一下找到了这俩坑。其他的基本就按教程配置就行，最后注意swig中字段和theme下的config.yml一致就可以。</p>]]></content:encoded>
      
      <comments>https://icewinechen.com/2018/08/30/gitment%E2%80%94%E2%80%94config/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
